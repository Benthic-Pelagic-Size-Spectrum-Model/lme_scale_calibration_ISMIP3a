{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0fc6a1-968c-467f-9a6c-5d15003d2364",
   "metadata": {},
   "source": [
    "# Running gridded DBPM run\n",
    "**Author**: Denisse Fierro Arcos  \n",
    "**Date**: 2025-01-13  \n",
    "\n",
    "Once all necessary inputs have been processed and fishing parameters calculated, we can finally run the gridded version of DBPM.  \n",
    "\n",
    "Note that the temporal range of DBPM inputs needs to be taken into account before running the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83d314-52dc-40d2-a95c-cac096a6a101",
   "metadata": {},
   "source": [
    "## Loading relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deff782b-529b-4f09-86ba-020ad634a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/g/data/vf71/la6889/lme_scale_calibration_ISMIP3a/new_workflow/')\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import useful_functions as uf\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd8f5a-65ee-4ac2-b1f5-603eebe44715",
   "metadata": {},
   "source": [
    "## Start a cluster for parallelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b17868f-906d-490c-b4ca-b5965141ec31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 15:25:09,761 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) _execute_subgraph(...)>\n",
      "new run_spec: <Task ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) _execute_subgraph(...)>\n",
      "old token: '362a2827097e72747b479dab2e477614'\n",
      "new token: '2a06d6e4001fc62ec8acd727236b2a4c'\n",
      "old dependencies: set()\n",
      "new dependencies: set()\n",
      "\n",
      "2025-01-13 15:25:40,561 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 15:26:26,913 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 15:32:06,142 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 15:39:42,319 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 15:40:38,255 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 15:52:44,456 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 16:11:59,931 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 16:38:08,586 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n",
      "2025-01-13 16:41:18,275 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: <Task ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0) getter(...)>\n",
      "new run_spec: Alias(('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)->('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old token: 'aa2a08b2f4c111f8ca9055f920789b3a'\n",
      "new token: ('Alias', ('open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0), ('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0))\n",
      "old dependencies: {'original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8'}\n",
      "new dependencies: {('original-open_dataset-size_bins-72c7f0fba951651fb99d2c971bf417b8', 0)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = Client(threads_per_worker = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c2ac5-dd94-499f-a499-5d8fc23f27f5",
   "metadata": {},
   "source": [
    "## Defining input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771407fd-01ca-43e2-9cba-fd1e58d0835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/g/data/vf71/la6889/dbpm_inputs/east_antarctica/gridded_params/'\n",
    "out_folder = '/g/data/vf71/la6889/dbpm_inputs/east_antarctica/run_fishing'\n",
    "os.makedirs(out_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507935e-32cf-40bb-b68e-60982b9d6739",
   "metadata": {},
   "source": [
    "## Loading fixed DBPM parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f5e881-ab0c-47e4-a369-7169a0a1a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = xr.open_zarr(\n",
    "     glob(os.path.join('/g/data/vf71/la6889/dbpm_inputs/east_antarctica/gridded', \n",
    "                      '*obsclim_deptho_*'))[0])['deptho']\n",
    "log10_size_bins_mat = xr.open_zarr('outputs/log10_size_bins_matrix.zarr/')['size_bins']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c7c78-d64d-4bba-b650-1ea25ec648a4",
   "metadata": {},
   "source": [
    "## Loading dynamic DBPM parameters\n",
    "Data for `predators`, `detritivores`, and `detritus` have an initialising timestep. This means that they start one month before all other parameters, but they end on the same date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b556260-200b-43cb-a7a9-6219e98b27a7",
   "metadata": {},
   "source": [
    "### `Predators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadba327-1284-4ea8-9d6c-fa2bd66b23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading initial predator data\n",
    "predators = xr.open_zarr(glob(\n",
    "    os.path.join(base_folder, \n",
    "                 'predators_spinup*1840*'))[0])['predators'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e3d82-218d-48a0-ad29-56494c275220",
   "metadata": {},
   "source": [
    "*Optional:* If DBPM could not be run for the entire decade covered by the original `predator` data, we can apply the following steps to start the model from any time step. **Remember**, you will need to ensure the `predator` data starts on time step before all other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f225362-358f-4692-a4ec-143c93c82eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load predator results for the month before you want to run DBPM\n",
    "p = xr.open_dataarray(os.path.join(out_folder, 'predators_15arcmin_fao-58_1841-08.nc'))\n",
    "#Subset predator data for the period you want to run the model\n",
    "predators = predators.sel(time = slice('1841-09', '1849-12'))\n",
    "#Combine both data arrays\n",
    "predators = xr.concat([p, predators], dim = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b71f8-083c-45e6-beac-9defcf89f925",
   "metadata": {},
   "source": [
    "### `Detritivores` and `detritus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a6c5c0-5bc1-425f-a55b-ebd0091db5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detritivores = xr.open_zarr(glob(\n",
    "#     os.path.join(base_folder, \n",
    "#                  'detritivores_*'))[0])['detritivores']\n",
    "\n",
    "# detritus = xr.open_zarr(glob(\n",
    "#     os.path.join(base_folder, \n",
    "#                  'detritus_*'))[0])['detritus']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b54dd-1f4e-4d59-8ad9-40903a921b29",
   "metadata": {},
   "source": [
    "*Optional:* If you are running DBPM from time than the start of the original `predator` data, you will need to load results for `detritivores` and `detritus` for the time step prior to the time step you want to start the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42acbc-cafb-4fea-867a-e440f7edd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "detritivores = xr.open_dataarray(os.path.join(out_folder, \n",
    "                                              'detritivores_15arcmin_fao-58_1841-08.nc'))\n",
    "\n",
    "detritus = xr.open_dataarray(os.path.join(out_folder,\n",
    "                                          'detritus_15arcmin_fao-58_1841-08.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb9f2e-71aa-4c6c-b45c-9fe98502f127",
   "metadata": {},
   "source": [
    "### Fishing `effort`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad5cb4-73b3-461d-8fc8-8ec3fa738e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "effort = xr.open_zarr(\n",
    "    glob(os.path.join(base_folder, \n",
    "                      'effort_spinup*'))[0])['effort']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c858f3cb-8e76-42b0-bbaf-a9a00a25ebbf",
   "metadata": {},
   "source": [
    "*Optional:* If you are running DBPM from time than the start of the original `predator` data, you will need to subset the data from the time step after you want to start the model, and load the `effort` results for the time step you want to start the model from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482509ae-89d3-47c8-9b05-e1fd397972a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load effort for time step DBPM starts\n",
    "e_start = xr.open_dataarray(os.path.join(out_folder, 'effort_15arcmin_fao-58_1841-09.nc'))\n",
    "#Subset effort data from the month after DBPM begins\n",
    "effort = effort.sel(time = slice('1841-10', '1849-12'))\n",
    "#Combine both data arrays\n",
    "effort = xr.concat([e_start, effort], dim = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4edfff-e39d-4ec9-b276-80815e927739",
   "metadata": {},
   "source": [
    "### Temperature effects for pelagic and benthic organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23aaf2ce-01d7-4adc-82b6-a486eaf74333",
   "metadata": {},
   "outputs": [],
   "source": [
    "pel_tempeffect = xr.open_zarr(glob(\n",
    "    os.path.join(base_folder, 'pel-temp-eff_spinup*'))[0])['pel_temp_eff']\n",
    "\n",
    "ben_tempeffect = xr.open_zarr(glob(\n",
    "    os.path.join(base_folder, 'ben-temp-eff_spinup*'))[0])['ben_temp_eff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea5dea-e92c-4a92-a288-f3c8164d4818",
   "metadata": {},
   "source": [
    "*Optional:* If you are running DBPM from time than the start of the original `predator` data, you will need to subset the data from the time step you want to start the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f0e4d1-8113-4192-81a2-92545d968ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pel_tempeffect = pel_tempeffect.sel(time = slice('1841-09', '1849-12'))\n",
    "ben_tempeffect = ben_tempeffect.sel(time = slice('1841-09', '1849-12'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51a7b4-4c24-43dd-852a-cd899d7cffd8",
   "metadata": {},
   "source": [
    "### Sinking rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e11e9e6-8371-4336-96e1-a04c16516e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinking_rate = xr.open_zarr(\n",
    "    glob(os.path.join('/g/data/vf71/la6889/dbpm_inputs/east_antarctica/gridded', \n",
    "                      '*_spinup_er_*'))[0])['export_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc25616-4c97-497a-b546-414bb39087a8",
   "metadata": {},
   "source": [
    "*Optional:* If you are running DBPM from time than the start of the original `predator` data, you will need to subset the data from the time step you want to start the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b5259-e9e9-406c-87f4-b515db42c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinking_rate = sinking_rate.sel(time = slice('1841-09', '1849-12'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53920e6f-d3bd-4b7a-821e-173864e83d39",
   "metadata": {},
   "source": [
    "## Running gridded DBPM\n",
    "Note that this may take several hours depending on computing resources, as well as the temporal and spatial range of the modelled area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474be3e-f21d-4020-86b7-3b82ac17031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.07/lib/python3.10/site-packages/dask/_task_spec.py:740: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    }
   ],
   "source": [
    "uf.gridded_sizemodel(base_folder, predators, detritivores, detritus, pel_tempeffect, \n",
    "                     ben_tempeffect, effort, sinking_rate, depth, log10_size_bins_mat,\n",
    "                     region = 'fao-58', out_folder = out_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08289a1-c69e-4565-b4cf-d7a31db2b78a",
   "metadata": {},
   "source": [
    "## Outside time loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd886c-29f0-4008-9e63-07d99e6a8279",
   "metadata": {},
   "source": [
    "### Fisheries catches per year per size class\n",
    "`fishing_mort_pred` and `fishing_mort_det` are set to zero outside the sizes for each class, so there is no need to apply a mask here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e54340d9-e8e4-45e8-bafc-7a3c15610c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_pred = fishing_mort_pred*predators*size_bin_vals\n",
    "catch_det = fishing_mort_det*detritivores*size_bin_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-24.07]",
   "language": "python",
   "name": "conda-env-analysis3-24.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
